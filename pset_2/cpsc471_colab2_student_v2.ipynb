{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this assignment\n",
    "In this assignment, you will implement two adversarial attacks against ResNet18 (FGSM and PGD), as well as two defenses against adversarial attacks (adversarial training and SAP). There are three goals for this assignment:\n",
    "1. Learning about and evaluate base adversarial attacks and defenses in a simple setting.\n",
    "2. Learning to use Pytorch's Lightning framework to simplify and modularize your code.\n",
    "3. Learning to use Pytorch to adjust/manipulate the *architecture* of a pretrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running this notebook in Colab, you'll want to uncomment and run the following line.\n",
    "\n",
    "If you're running this notebook locally or on a Grace cluster, you can separately install any packages you use. \n",
    "\n",
    "Note: for this assignment, if your local machine is not GPU-compatible, you will probably want to use Colab or a Grace cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import lightning as L\n",
    "from torchmetrics import Accuracy\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n",
    "Just run the next code block, but double check the one after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "NUM_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you run into memory issues, you can reduce the batch size\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Change these to the relative paths you'd like to use\n",
    "# for the CIFAR-10 data and model checkpoints\n",
    "DATA_PATH = 'data/'\n",
    "CHECKPOINT_PATH = 'models/checkpoints/'\n",
    "\n",
    "# The different models we'll be fine-tuning\n",
    "SAVE_NAMES = [\n",
    "    'baseline',\n",
    "    'adv_train',    # Adversarial training a la Madry et al.\n",
    "    'SAP_conv', # Full SAP post-convolution a la Dhillon et al.\n",
    "]\n",
    "SAVE_NAMES = {\n",
    "    name: os.path.join(CHECKPOINT_PATH, name) for name in SAVE_NAMES\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results dictionary\n",
    "We set up for storing experiment results here. Just run the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {name: None for name in SAVE_NAMES.keys()}\n",
    "attacks = {\n",
    "    'id': None,\n",
    "    'fgsm': None,\n",
    "    'pgd': None,\n",
    "}\n",
    "\n",
    "results_dic = {\n",
    "    'model': [],\n",
    "    'attack': [],\n",
    "    'top_k': [],\n",
    "    'accuracy': [],\n",
    "}\n",
    "results_trainer = L.Trainer(accelerator='auto', devices=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "You can just run these three blocks of code. They import the CIFAR10 data from Torchvision and split them into train/validation/test sets.\n",
    "\n",
    "We also takes a sample for later visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained normalization based on https://discuss.pytorch.org/t/how-to-preprocess-input-for-pre-trained-networks/683\n",
    "means, stds = [0.49139968, 0.48215827, 0.44653124], [0.24703233, 0.24348505, 0.26158768]\n",
    "means, stds = np.array(means), np.array(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "def get_cifar_loaders(batch_size):\n",
    "    # Transformations applied to images before passing them to the model\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            # transforms.Resize(256),\n",
    "            # transforms.CenterCrop(224),\n",
    "            transforms.ToImage(), # Converts to tensor\n",
    "            transforms.ToDtype(torch.float32, scale=True),\n",
    "            transforms.Normalize(mean=means, std=stds)\n",
    "        ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root=DATA_PATH, train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    # The train set is of size 50000\n",
    "    trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root=DATA_PATH, train=False,\n",
    "                                        download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "    \n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader, testloader = get_cifar_loaders(BATCH_SIZE)\n",
    "sample_images, sample_labels = next(iter(trainloader))\n",
    "sample_images, sample_labels = sample_images.to(device), sample_labels.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Resnet Class\n",
    "Here we've implemented a ResNet18 model in the Pytorch Lightning framework. Here is [Lightning's documentation](https://lightning.ai/docs/pytorch/stable/).\n",
    "\n",
    "The main code to look at are ```__init__``` and ```training_step```. If you'd like to use Lightning on your own project, the other methods may be useful reference, but as always we defer to the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LResnet(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Set loss module\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "        # Example input for visualizing the graph in Tensorboard\n",
    "        # CIFAR-10 images are 32x32\n",
    "        self.example_input_array = torch.zeros((1, 3, 32, 32), dtype=torch.float32)\n",
    "        self.num_target_classes = 10\n",
    "        # Accuracy metric for training logs and testing evaluation\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_target_classes, top_k=1)\n",
    "        # Adversarial generation method for training\n",
    "        self.adv_train_method = None\n",
    "\n",
    "        # Load pretrained model weights\n",
    "        self.model = torchvision.models.resnet18(\n",
    "            weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "        # Change final layer from 1000 (ImageNet) classes to 10 (CIFAR-10) classes\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, self.num_target_classes)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        return self.model(imgs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-5, weight_decay=0.1)\n",
    "        return [optimizer] # Lightning has enables multi-optimizer training, e.g. for GANs\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        if self.adv_train_method is not None:\n",
    "            opt = self.optimizers()\n",
    "            opt.zero_grad()\n",
    "            # Change the images to adversarial examples\n",
    "            imgs = self.adv_train_method(self.model, imgs, labels)\n",
    "            # adv_train_method sets the model to eval\n",
    "            self.model.train()\n",
    "            # Reset accumulated gradients from adversarial generation\n",
    "            opt.zero_grad()\n",
    "        # Once we have the correct training images,\n",
    "        # we can use the usual Lightning forward pass\n",
    "        outputs = self.model(imgs)\n",
    "        loss = self.loss_module(outputs, labels)\n",
    "        acc = self.accuracy(outputs, labels)\n",
    "        # Log accuracy and loss per-batch for Tensorboard\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        outputs = self.model(imgs)\n",
    "        loss = self.loss_module(outputs, labels)\n",
    "        self.log('val_loss', loss)\n",
    "        # No need to return to call backward() on the loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        outputs = self.model(imgs)\n",
    "        acc = self.accuracy(outputs, labels)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "        # No need to return to call backward() on the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example training code\n",
    "Run the following code block. It is an example of how to code a training loop with Lightning. If you change hyperparameters for your experiments later, you will need to comment at the end on the changes you've made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_key = 'baseline'\n",
    "baseline_model = LResnet()\n",
    "baseline_trainer = L.Trainer(\n",
    "    default_root_dir = SAVE_NAMES[save_key], # Where to save the model\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    max_epochs=30,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint( # Save the best model by validation loss\n",
    "            dirpath=SAVE_NAMES[save_key],\n",
    "            monitor='val_loss',\n",
    "            save_top_k=1,\n",
    "            mode='min',\n",
    "            save_weights_only=True,\n",
    "            every_n_epochs=1,\n",
    "        ),\n",
    "        EarlyStopping( # Stop training early if val_loss doesn't improve\n",
    "            monitor='val_loss', \n",
    "            patience=3, \n",
    "            verbose=True, \n",
    "            mode='min',\n",
    "        ),\n",
    "        LearningRateMonitor('epoch') # Log learning rate each epoch\n",
    "    ],\n",
    ")\n",
    "\n",
    "# These two lines are optional, but they make the Tensorboard logs look nicer\n",
    "baseline_trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "baseline_trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "# This is all you need to train the model\n",
    "baseline_trainer.fit(baseline_model, trainloader, valloader)\n",
    "# Load best checkpoint after training\n",
    "baseline_model = LResnet.load_from_checkpoint(\n",
    "    baseline_trainer.checkpoint_callback.best_model_path\n",
    ").to(device)\n",
    "\n",
    "# Store the model in the dictionary\n",
    "models[save_key] = baseline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial attacks\n",
    "Implement the FGSM and PGD attacks. These are white-box evasion attacks, and they were covered in class. Make sure that the final outputs are detached!\n",
    "\n",
    "Once you finish this part and the previous one, you can head to the Experiments section to test your attacks on the baseline (pretrained) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used as a baseline\n",
    "def id(model, imgs, labels):\n",
    "    return imgs.detach()\n",
    "\n",
    "def fgsm(model, imgs, labels):\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "        model (nn.Module): Model to attack, e.g. self.model in the LResnet definition.\n",
    "        imgs (Tensor): Tensor of images. Size (BATCH_SIZE, C, H, W). Normalized according to means, stds.\n",
    "        labels (Tensor): Tensor of labels. Size (BATCH_SIZE,). Each element is an integer in [0, NUM_CLASSES).\n",
    "    Returns:\n",
    "        adv_imgs (Tensor): Adversarial images. Same dimensions and normalization as imgs. Detached.\n",
    "            Each adversarial image in the batch is L_infinity distance at most eps away from the original image.\n",
    "            Images generated by the Fast Gradient Sign Method (FGSM).\n",
    "    \"\"\"\n",
    "    eps = 8/255 # Maximum perturbation\n",
    "    model.eval()\n",
    "    loss_to_use = nn.CrossEntropyLoss()\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def pgd(model, imgs, labels):\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "        model (nn.Module): Model to attack, e.g. self.model in the LResnet definition.\n",
    "        imgs (Tensor): Tensor of images. Size (BATCH_SIZE, C, H, W). Normalized according to means, stds.\n",
    "        labels (Tensor): Tensor of labels. Size (BATCH_SIZE,). Each element is an integer in [0, NUM_CLASSES).\n",
    "    Returns:\n",
    "        adv_imgs (Tensor): Adversarial images. Same dimensions and normalization as imgs. Detached.\n",
    "            Each adversarial image in the batch is L_infinity distance at most eps away from the original image.\n",
    "            Images generated by the Projected Gradient Descent (PGD)\n",
    "    \"\"\"\n",
    "    iters = 20 # Number of steps in PGD\n",
    "    eps = 8/255 # Maximum perturbation\n",
    "    alpha = 2/255 # Step size\n",
    "    model.eval()\n",
    "    loss_to_use = nn.CrossEntropyLoss()\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "attacks['id'] = id\n",
    "attacks['fgsm'] = fgsm\n",
    "attacks['pgd'] = pgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the slides for Lecture 08 on Adversarial Evasion, page 26, on FGSM. Compare and contrast the two variants shown. Under what circumstances would you choose the one method over the other?\n",
    "\n",
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Defenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Training\n",
    "Implement the training loop for an adversarially trained model using PGD as the adversarial example generation method.\n",
    "\n",
    "Your code should look very similar to the baseline example above. Be sure to save your model in the right place and to store your model in the ```models``` dictionary. You can adjust ```max_epochs``` (although early stopping should handle the cases you'd want to) or any other hyperparameters if you'd like. You will need to comment at the end on any changes you've made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_key = 'adv_train'\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Store the model in the dictionary\n",
    "models[save_key] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAP\n",
    "### Function implementation\n",
    "Implement a function that applies [Stochastic Activation Pruning](https://arxiv.org/pdf/1803.01442.pdf) (SAP) to a Tensor. Also read the description from the [Obfuscated Gradients](https://arxiv.org/pdf/1802.00420.pdf) paper (SAP is described in Section 5.3.1).\n",
    "\n",
    "Roughly, the algorithm keeps each activation from the previous layer (or, generally, Module) with probability proportional to its absolute value, making this choice independently for each activation, and rescales the kept activations so that the average total activation is not changed.\n",
    "\n",
    "That is:\n",
    "1. Let the activation being passed in (from a single image, i.e. assuming batch size 1) be $act$.\n",
    "2. Let $p$ be the same shape as the feature $act$, with values proportional to $|act|$ (absolute value applied element-wise) and sum 1.\n",
    "3. Let $N$ be the number of entries in the feature. Draw $N$ times *with replacement* from the entries with probability mass function $p$. Set the selected entries to 1 and the remaining entries to 0 in a Tensor $m$ of the same shape as $p$ (and therefore $act$).\n",
    "4. Apply the mask to get $act \\circ m$ (element-wise multiplication). Divide each entry by the probability of keeping that entry (i.e. having corresponding 1 in $m$). Return the result.\n",
    "\n",
    "Now, the above method runs very slowly. Here's another approach that the authors of Obfuscated Gradients actually use instead:  \n",
    "- Essentially, if we leave each entry with the same probability of being selected as in the original SAP method, but assume we choose whether or not to keep each entry independently (instead of drawing with replacement from all the entries many times), we get a much faster filter. Specifically, once we get $p$ and $N$, the probability of keeping entry $j$ is $q:=1-e^{-Np_j}$. Consider it an exercise to prove that this is the case :)\n",
    "- For the reason from the \"Bonus\" part at the end of this assignment, the authors of Obfuscated Gradients use probability $1-e^{-2Np_j}.$ Do this as well.\n",
    "- Normalization is easier because $q$ is records precisely the probability of keeping each entry.\n",
    "- The time-save is mostly in vectorization.\n",
    "\n",
    "You may use either approach, although the latter is *much* faster.\n",
    "\n",
    "Read the above papers for more details. You may also find [Erratum](https://arxiv.org/abs/2010.00071) interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sap(act):\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "        act (Tensor): Tensor of activations of shape (K, C, H, W), where K is the batch size.\n",
    "        The values of C, H, W depend on the layer.\n",
    "    Returns:\n",
    "        Tensor of the same shape as act, masked and rescaled according to the SAP method.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closely study Algorithm 1 from the SAP paper. Line 8 draws from a categorical distribution with probabilities $p^i$. Explain what this means: if a neuron has $p_j = 0.3$, what happens over $r^i$ samples? Explain your answer intuitively. Why do you think we need line 13 in Algorithm 1?\n",
    "\n",
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted Model\n",
    "The change you need to make to apply the defense to a ResNet model is simple: simply replace each Conv2d module with a very similar module that applies SAP immediately after convolution. Run the next block and complete the one after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAP_Conv2d(nn.Conv2d):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            groups=1,\n",
    "            bias=True,\n",
    "            dilation=1,\n",
    "    ):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                         padding, dilation, groups, bias)\n",
    "        \n",
    "    # This is the important part\n",
    "    def _conv_forward(self, input, weight, bias):\n",
    "        act = super()._conv_forward(input, weight, bias)\n",
    "        masked_act = sap(act)\n",
    "        return masked_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms LResnet to use SAP_Conv2d instead of nn.Conv2d\n",
    "def to_sap_conv(model):\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "        model (LResnet): Model to modify.\n",
    "    Returns:\n",
    "        None. The model is modified in place.\n",
    "        EVERY nn.Conv2d layer is replaced with SAP_Conv2d.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Consider using recursion on `model.model.modules()` –> iterates through its submodules\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Train an LResnet defended by SAP.\n",
    "\n",
    "Your code should look very similar to the baseline example above. Be sure to save your model in the right place and to store your model in the ```models``` dictionary. You can adjust ```max_epochs``` (although early stopping should handle the cases you'd want to) or any other hyperparameters if you'd like. You will need to comment at the end on any changes you've made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_key = 'SAP_conv'\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Store the model in the dictionary\n",
    "models[save_key] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "These two functions help us modularize the experiments we run. Complete ```eval_attack``` to compute the accuracy of each model (baseline, adversarially trained, SAP) on images. We take every batch in ```loader```, apply ```attack_method``` to the batch, and check the accuracy of ```model``` in predicting the class of each adversarial image. Output a Float between 0 and 1.\n",
    "\n",
    "```top_k``` describes how we determine accuracy. For example, ```top_k=2``` means if the model predicts the correct class within its two highest-scoring classes, it's counted as correct.\n",
    "\n",
    "Complete the next code block and just run the one after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_attack(model, attack_method, loader, top_k, max_batches=0):\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "        model (LResnet): Model to attack.\n",
    "        attack_method (function): Adversarial generation method. One of id, fgsm, pgd.\n",
    "        loader (DataLoader): Data loader for the dataset to evaluate on.\n",
    "        top_k (int): The number of top predictions to check for correctness.\n",
    "        max_batches (int): Maximum number of batches to evaluate. If 0, evaluate on the entire dataloader.\n",
    "    Returns:\n",
    "        float: Accuracy of the model on the (adversarially perturbed) dataset.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, attack, top_k=1, max_batches=0):\n",
    "    # If we're re-running an experiment, remove the old results\n",
    "    for i in range(len(results_dic['model'])):\n",
    "        if results_dic['model'][i] == model and results_dic['attack'][i] == attack and results_dic['top_k'][i] == top_k:\n",
    "            results_dic['model'].pop(i)\n",
    "            results_dic['attack'].pop(i)\n",
    "            results_dic['top_k'].pop(i)\n",
    "            results_dic['accuracy'].pop(i)\n",
    "            break\n",
    "    # Run the experiment\n",
    "    acc = eval_attack(\n",
    "        models[model], \n",
    "        attacks[attack], \n",
    "        testloader, \n",
    "        top_k=top_k, \n",
    "        max_batches=max_batches\n",
    "    )\n",
    "    # Store the results\n",
    "    results_dic['model'].append(model)\n",
    "    results_dic['attack'].append(attack)\n",
    "    results_dic['top_k'].append(top_k)\n",
    "    results_dic['accuracy'].append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "The following code runs experiments with all three attacks (including the baseline identity) on the baseline model. Feel free to adjust the parameters or code how you'd like. You will need to comment later on any adjustments you've made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attack_method in ['id', 'fgsm', 'pgd']:\n",
    "    print(f\"Running experiment baseline with attack {attack_method}...\")\n",
    "    mb = 0\n",
    "    # I've found 100 batches about matches the time of the other attacks' experiments\n",
    "    if attack_method == 'pgd':\n",
    "        mb = 100\n",
    "    run_experiment('baseline', attack_method, max_batches=mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarially trained\n",
    "Run the same experiments on the adversarially trained model. You should be able to use very similar code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAP\n",
    "Run the same experiments on the model defended by SAP. You should be able to use very similar code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with the `top_k` value in `run_experiment` (which is passed down to `eval_attack`). What is the largest `top_k`, from your results, such that the baseline performs at a similar level as the SAP-defended model kept with `top_k=1`. \n",
    "\n",
    "Note that this value of `top_k` that offers the baseline as much flexibility as possible, but is also an important indication of how incorrect the baseline will become if attacked. It is also an indication of how much more robust your SAP-defended model is compared to the baseline if it's able to do well with just `top_k=1`.\n",
    "\n",
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results\n",
    "We've already stored the results in a dictionary. Let's put them in a Pandas DataFrame to make them nicer to look at. Export your results to a CSV to save them.\n",
    "\n",
    "It might take some manual work, but if you run any training loop more than once you should probably keep track, e.g. in a spreadsheet or in file names, of which one is which. In particular, always ensure you will know which model is the most recently trained: even better, ensure you'll still know in a month or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results_dic)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "Use the cell below to open a Tensorboard session, and check out the train accuracy/loss and validation loss over the training period. Take screenshots or export images of some salient graphs. Briefly describe what you notice. See [the documentation](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb) to find how to use Tensorboard with Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final question\n",
    "Comment on your results and any adjustments you've made to the experiments. What did you expect? What met or differed from your expectations? How would you compare the attacks? How would you compare the defenses (in raw performance? in performance against adversarial examples? in training time?)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "Technically, because SAP is stochastic, the authors average the outputs of 100 runs. Try implementing this. How does the model's regular performance change? How does its performance against adversarial attacks change?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
